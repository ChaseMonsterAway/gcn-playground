{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from spektral.layers import GraphConv, GlobalAvgPool, EdgeConditionedConv\n",
    "\n",
    "from spektral.utils import Batch, batch_iterator\n",
    "from spektral.utils import label_to_one_hot, normalized_laplacian\n",
    "from spektral.layers.ops import sp_matrix_to_sp_tensor\n",
    "\n",
    "import graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "SEED = 2020\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_random_seed(SEED)\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, _ = mnist.load_data()\n",
    "X_train, X_val, X_test = X_train[..., None], X_val[..., None], X_test[..., None]\n",
    "N = X_train.shape[-2]      # Number of nodes in the graphs\n",
    "F = X_train.shape[-1]      # Node features dimensionality\n",
    "n_out = 10  # Dimension of the target\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_graph(m, k=8, corners=False):\n",
    "    '''\n",
    "    To create adjacency matrix as per Defferrard et al. 2016\n",
    "    '''\n",
    "    z = graph.grid(m)\n",
    "    dist, idx = graph.distance_sklearn_metrics(z, k=k, metric='euclidean')\n",
    "    A = graph.adjacency(dist, idx)\n",
    "\n",
    "    # Connections are only vertical or horizontal on the grid.\n",
    "    # Corner vertices are connected to 2 neightbors only.\n",
    "    if corners:\n",
    "        import scipy.sparse\n",
    "        A = A.toarray()\n",
    "        A[A < A.max()/1.5] = 0\n",
    "        A = scipy.sparse.csr_matrix(A)\n",
    "        print('{} edges'.format(A.nnz))\n",
    "\n",
    "    print(\"{} > {} edges\".format(A.nnz//2, k*m**2//2))\n",
    "    return A\n",
    "\n",
    "\n",
    "def draw_graph(A, m=28, ax=None, spring_layout=False, size_factor=10):\n",
    "    '''Draw the graph given adjacency matrix(A),\n",
    "    optionally with spring_layout.\n",
    "    '''\n",
    "    assert m**2 == A.shape[0] == A.shape[1]\n",
    "    # Create the nx.Graph object\n",
    "    G = nx.from_scipy_sparse_matrix(A)\n",
    "    print('Number of nodes: %d; Number of edges: %d' % \\\n",
    "          (G.number_of_nodes(), G.number_of_edges()))\n",
    "    grid_coords = graph.grid(m)\n",
    "\n",
    "    if spring_layout:\n",
    "        # remove nodes without edges\n",
    "        nodes_without_edges = [n for n, k in  G.degree() if k == 0]\n",
    "        G.remove_nodes_from(nodes_without_edges)\n",
    "        print('After removing nodes without edges:')\n",
    "        print('Number of nodes: %d; Number of edges: %d' % \\\n",
    "              (G.number_of_nodes(), G.number_of_edges()))\n",
    "    \n",
    "    z = graph.grid(m)\n",
    "    \n",
    "    # initial positions\n",
    "    pos = {n: z[n] for n in G.nodes()} \n",
    "    \n",
    "    if spring_layout:\n",
    "        pos = nx.spring_layout(G, \n",
    "                               pos=pos,\n",
    "                               iterations=200)\n",
    "    \n",
    "    ax = nx.draw(G, pos,\n",
    "                 node_size=[G.degree(n) * size_factor for n in G.nodes()],\n",
    "                 ax=ax\n",
    "                )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = grid_graph(28, k=8)\n",
    "plt.imshow(A.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the graph\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax = draw_graph(A, ax=ax, size_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = draw_graph(A, ax=ax, size_factor=1, spring_layout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature graph as a 2D Euclidean grid in the entire space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(20, 5), ncols=4)\n",
    "\n",
    "axes[0].imshow(A.todense())\n",
    "axes[0].set_title('$A$')\n",
    "\n",
    "# degree matrix D\n",
    "D = A.sum(axis=0).reshape(28, 28)\n",
    "axes[1].imshow(D)\n",
    "axes[1].set_title('$D$')\n",
    "\n",
    "axes[2] = draw_graph(A, ax=axes[2], size_factor=1)\n",
    "axes[3] = draw_graph(A, ax=axes[3], size_factor=1, spring_layout=True)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature graphs as a \"pruned\" grid for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# threshold = 0.25 # to reduce the noise for averaged signals\n",
    "threshold = 0.5\n",
    "d_digit_graphs = {} # to collect feature graphs from each class\n",
    "\n",
    "for i in range(10):\n",
    "    mask = y_train == i\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(20, 5), ncols=4)\n",
    "\n",
    "    x_train_i_avg = X_train[mask].mean(axis=0).flatten()\n",
    "    axes[0].imshow(x_train_i_avg.reshape(28, 28))\n",
    "\n",
    "    # threshold the averages of pixels\n",
    "    x_train_i_avg[x_train_i_avg < threshold] = 0\n",
    "    axes[1].imshow(x_train_i_avg.reshape(28, 28))\n",
    "\n",
    "    # a sparse diag matrix with the intensities values on the diagnoal\n",
    "    A_diag_i = sp.diags(x_train_i_avg, dtype=np.float32).tolil()\n",
    "\n",
    "    # \"prune\" the adjacency of the grid graph to preserve the subgraph with the data\n",
    "    A_i = A.dot(A_diag_i)\n",
    "    d_digit_graphs[i] = A_i\n",
    "    \n",
    "    axes[2] = draw_graph(A_i, ax=axes[2], size_factor=1)\n",
    "    \n",
    "    axes[3] = draw_graph(A_i, ax=axes[3], size_factor=1, spring_layout=True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph convolutional network for classification with different feature graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "l2_reg = 5e-4         # Regularization rate for l2\n",
    "learning_rate = 0.03  # Learning rate for SGD\n",
    "batch_size = 100       # Batch size\n",
    "epochs = 20         # Number of training epochs\n",
    "# es_patience = 10     # Patience fot early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D, Reshape\n",
    "from spektral.layers import GraphConv, ChebConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCN_single_layer(A, N=28*28, F=1,\n",
    "                     n_out=10,\n",
    "                     l2_reg=l2_reg, \n",
    "                     learning_rate=learning_rate,\n",
    "                    ):\n",
    "    # Computes a normalized Laplacian (as the conv filter)\n",
    "    L = normalized_laplacian(A)\n",
    "    \n",
    "    # Model definition\n",
    "    # N: Number of nodes in the graphs\n",
    "    # F: Node features dimensionality\n",
    "    X_in = Input(shape=(N, F))\n",
    "    # Pass A as a fixed tensor, otherwise Keras will complain about inputs of\n",
    "    # different rank.\n",
    "    A_in = Input(tensor=sp_matrix_to_sp_tensor(L))\n",
    "\n",
    "#     graph_conv = GraphConv(10,\n",
    "#                            activation='relu',\n",
    "#                            kernel_regularizer=l2(l2_reg),\n",
    "#                            use_bias=True)([X_in, A_in])\n",
    "    graph_conv = ChebConv(10,\n",
    "                           activation='relu',\n",
    "                           kernel_regularizer=l2(l2_reg),\n",
    "                           use_bias=True)([X_in, A_in])\n",
    "\n",
    "    fc = Flatten()(graph_conv)\n",
    "    output = Dense(n_out, activation='softmax')(fc)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=[X_in, A_in], outputs=output)\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def GCN(A, N=28*28, F=1,\n",
    "        n_out=10,\n",
    "        l2_reg=l2_reg, \n",
    "        learning_rate=learning_rate,\n",
    "       ):\n",
    "    '''Build a graph convolution network given A.\n",
    "    '''\n",
    "    # Computes a normalized Laplacian (as the conv filter)\n",
    "    L = normalized_laplacian(A)\n",
    "    \n",
    "    # Model definition\n",
    "    # N: Number of nodes in the graphs\n",
    "    # F: Node features dimensionality\n",
    "    X_in = Input(shape=(N, F))\n",
    "    \n",
    "    # Pass A as a fixed tensor, otherwise Keras will complain about inputs of\n",
    "    # different rank.\n",
    "    A_in = Input(tensor=sp_matrix_to_sp_tensor(L))\n",
    "\n",
    "    graph_conv = GraphConv(32,\n",
    "                           activation='relu',\n",
    "                           kernel_regularizer=l2(l2_reg),\n",
    "                           use_bias=True)([X_in, A_in])\n",
    "    graph_conv = GraphConv(32,\n",
    "                           activation='relu',\n",
    "                           kernel_regularizer=l2(l2_reg),\n",
    "                           use_bias=True)([graph_conv, A_in])\n",
    "    \n",
    "    rs = Reshape((28, 28, 32))(graph_conv)\n",
    "    pooled = MaxPooling2D(pool_size=(2, 2))(rs)\n",
    "    flatten = Flatten()(pooled)\n",
    "    fc = Dense(512, activation='relu')(flatten)\n",
    "    output = Dense(n_out, activation='softmax')(fc)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=[X_in, A_in], outputs=output)\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Model with full grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original model params\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.nnz)\n",
    "model_full_grid = GCN_single_layer(A)\n",
    "model_full_grid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "validation_data = (X_val, y_val)\n",
    "model_full_grid.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=validation_data,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print('Evaluating model.')\n",
    "eval_results = model_full_grid.evaluate(X_test,\n",
    "                              y_test,\n",
    "                              batch_size=batch_size)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test acc: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN model with an empty adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A0 = sp.csr_matrix(A.shape, dtype=np.float32)\n",
    "print(A0.shape)\n",
    "\n",
    "model_no_graph = GCN_single_layer(A0)\n",
    "model_no_graph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_no_graph.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=validation_data,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print('Evaluating model.')\n",
    "eval_results = model_no_graph.evaluate(X_test,\n",
    "                              y_test,\n",
    "                              batch_size=batch_size)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test acc: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_model(N=28*28, F=1,\n",
    "                     n_out=10,\n",
    "                     l2_reg=l2_reg, \n",
    "                     learning_rate=learning_rate):\n",
    "    \n",
    "    X_in = Input(shape=(N, F))\n",
    "    \n",
    "    fc = Dense(10, activation='relu',\n",
    "               kernel_regularizer=l2(l2_reg),\n",
    "               use_bias=True)(Flatten()(X_in))\n",
    "    \n",
    "    output = Dense(n_out, activation='softmax')(fc)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=X_in, outputs=output)\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc = fc_model()\n",
    "model_fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_fc.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=validation_data,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print('Evaluating model.')\n",
    "eval_results = model_fc.evaluate(X_test,\n",
    "                              y_test,\n",
    "                              batch_size=batch_size)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test acc: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with digit feature graph as conv filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[mask].reshape(-1, 784).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = metrics.pairwise_distances(X_train[mask].reshape(-1, 784).T, metric='cosine', n_jobs=-2)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.min(), d.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d.flatten(), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 1 - d\n",
    "W = sp.coo_matrix(W, dtype=np.float32)\n",
    "\n",
    "# No self-connections.\n",
    "W.setdiag(0)\n",
    "\n",
    "# Non-directed graph.\n",
    "bigger = W.T > W\n",
    "W = W - W.multiply(bigger) + W.T.multiply(bigger)\n",
    "\n",
    "assert W.nnz % 2 == 0\n",
    "assert np.abs(W - W.T).mean() < 1e-10\n",
    "assert type(W) is sp.csr.csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W.multiply(W > 0.8)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_train == 7\n",
    "d, idx = graph.distance_sklearn_metrics(X_train[mask].reshape(-1, 784).T, k=4, \n",
    "                                        metric='cosine'\n",
    "                                       )\n",
    "print(d.shape, idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = graph.adjacency(d, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, k = d.shape\n",
    "\n",
    "# Weight matrix.\n",
    "I = np.arange(0, M).repeat(k)\n",
    "J = idx.reshape(M*k)\n",
    "# J = np.arange(0, M).repeat(k)\n",
    "V = (1-d).reshape(M*k)\n",
    "nnz_mask = V > 0\n",
    "W = sp.coo_matrix((V[nnz_mask], (I[nnz_mask], J[nnz_mask])), shape=(M, M))\n",
    "\n",
    "# No self-connections.\n",
    "W.setdiag(0)\n",
    "\n",
    "# Non-directed graph.\n",
    "bigger = W.T > W\n",
    "W = W - W.multiply(bigger) + W.T.multiply(bigger)\n",
    "\n",
    "assert W.nnz % 2 == 0\n",
    "assert np.abs(W - W.T).mean() < 1e-10\n",
    "assert type(W) is sp.csr.csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.min(), V.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(W.toarray().flatten(), bins=50, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = graph.adjacency(d, idx)\n",
    "print(W.shape, W.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "draw_graph(W, ax=ax, size_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "draw_graph(W, ax=ax, size_factor=1, spring_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_digit_corr_graphs = {} # build digit feature graph by correlation\n",
    "\n",
    "# this way of constructing feature graphs enable \n",
    "# the GCN to not only see pixels locally, but also globally based on known patterns\n",
    "\n",
    "for i in range(10):\n",
    "    mask = y_train == i\n",
    "    \n",
    "    dist = metrics.pairwise_distances(X_train[mask].reshape(-1, 784).T, metric='cosine', n_jobs=-2)\n",
    "    \n",
    "    W = sp.coo_matrix(1 - dist, dtype=np.float32)\n",
    "\n",
    "    # No self-connections.\n",
    "    W.setdiag(0)\n",
    "\n",
    "    # Non-directed graph.\n",
    "    bigger = W.T > W\n",
    "    W = W - W.multiply(bigger) + W.T.multiply(bigger)\n",
    "\n",
    "    assert W.nnz % 2 == 0\n",
    "    assert np.abs(W - W.T).mean() < 1e-10\n",
    "    assert type(W) is sp.csr.csr_matrix    \n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(15, 5), ncols=3)\n",
    "\n",
    "    x_train_i_avg = X_train[mask].mean(axis=0).flatten()\n",
    "    axes[0].imshow(x_train_i_avg.reshape(28, 28))\n",
    "\n",
    "    # thresholding \n",
    "    W = W.multiply(W > 0.8)\n",
    "\n",
    "    d_digit_corr_graphs[i] = W\n",
    "    \n",
    "    axes[1] = draw_graph(W, ax=axes[1], size_factor=1)\n",
    "    \n",
    "    axes[2] = draw_graph(W, ax=axes[2], size_factor=1, spring_layout=True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = metrics.pairwise_distances(X_train.reshape(-1, 784).T, metric='cosine', n_jobs=-2)\n",
    "\n",
    "W = sp.coo_matrix(1 - dist, dtype=np.float32)\n",
    "\n",
    "# No self-connections.\n",
    "W.setdiag(0)\n",
    "\n",
    "# Non-directed graph.\n",
    "bigger = W.T > W\n",
    "W = W - W.multiply(bigger) + W.T.multiply(bigger)\n",
    "\n",
    "assert W.nnz % 2 == 0\n",
    "assert np.abs(W - W.T).mean() < 1e-10\n",
    "assert type(W) is sp.csr.csr_matrix    \n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 5), ncols=3)\n",
    "\n",
    "x_train_i_avg = X_train.mean(axis=0).flatten()\n",
    "axes[0].imshow(x_train_i_avg.reshape(28, 28))\n",
    "\n",
    "# thresholding \n",
    "W = W.multiply(W > 0.8)\n",
    "\n",
    "d_digit_corr_graphs[i] = W\n",
    "\n",
    "axes[1] = draw_graph(W, ax=axes[1], size_factor=1)\n",
    "\n",
    "axes[2] = draw_graph(W, ax=axes[2], size_factor=1, spring_layout=True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_digit_models = {}\n",
    "for digit in range(10):\n",
    "#     model_i = GCN_single_layer(d_digit_graphs[digit])\n",
    "    model_i = GCN_single_layer(d_digit_corr_graphs[digit])\n",
    "    print(digit, d_digit_graphs[digit].nnz)\n",
    "#     model_0.summary()\n",
    "\n",
    "    # Train model with digit feature graph\n",
    "    model_i.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=validation_data,\n",
    "                        epochs=epochs)\n",
    "    \n",
    "    d_digit_models[digit] = model_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for digit, model_i in d_digit_models.items():\n",
    "    eval_results = model_i.evaluate(X_test,\n",
    "                                  y_test,\n",
    "                                  batch_size=batch_size)\n",
    "    print('Digit %d' % digit)\n",
    "    print('Test loss: {}\\n'\n",
    "          'Test acc: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def plot_confusion_matrix(cm, classes=list(range(10))):\n",
    "    cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax = sns.heatmap(cm_df, \n",
    "#                      fmt='d', \n",
    "                     fmt='.3f',\n",
    "                     annot=True, cmap='Reds', ax=ax)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_preds = model_full_grid.predict(X_test)\n",
    "print(y_test_preds.shape)\n",
    "cm = metrics.confusion_matrix(y_test, np.argmax(y_test_preds, axis=1))\n",
    "fig = plot_confusion_matrix(cm/cm.sum(axis=1))\n",
    "fig.get_axes()[0].set_title('Full grid graph');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_preds = model_no_graph.predict(X_test)\n",
    "print(y_test_preds.shape)\n",
    "cm = metrics.confusion_matrix(y_test, np.argmax(y_test_preds, axis=1))\n",
    "fig = plot_confusion_matrix(cm/cm.sum(axis=1))\n",
    "fig.get_axes()[0].set_title('No graph');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = {}\n",
    "\n",
    "for model_name, model in d_digit_models.items():\n",
    "    \n",
    "    y_test_preds = model.predict(X_test)\n",
    "    cm = metrics.confusion_matrix(y_test, np.argmax(y_test_preds, axis=1))\n",
    "    \n",
    "#     y_train_preds = model.predict(X_train)\n",
    "#     cm = metrics.confusion_matrix(y_train, np.argmax(y_train_preds, axis=1))\n",
    "    \n",
    "#     acc_per_classes = np.diag(cm/cm.sum(axis=1))\n",
    "    acc_per_classes = np.diag(cm)\n",
    "    \n",
    "    acc_df[model_name] = acc_per_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame.from_dict(acc_df)\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = model_full_grid.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, np.argmax(y_test_preds, axis=1))\n",
    "\n",
    "# y_train_preds = model_full_grid.predict(X_train)\n",
    "# cm = metrics.confusion_matrix(y_train, np.argmax(y_train_preds, axis=1))\n",
    "\n",
    "\n",
    "# acc_per_class_full_model = np.diag(cm/cm.sum(axis=1))\n",
    "acc_per_class_full_model = np.diag(cm)\n",
    "acc_per_class_full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy gain compared to full model\n",
    "sns.heatmap(acc_df - acc_per_class_full_model,\n",
    "            cmap='RdBu_r',\n",
    "#             vmin=-0.15,\n",
    "#             vmax=0.15\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy gain compared to 10 averaged models\n",
    "sns.heatmap(acc_df - acc_df.mean(axis=1),\n",
    "            cmap='RdBu_r',\n",
    "#             vmin=-0.15,\n",
    "#             vmax=0.15\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = model_no_graph.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, np.argmax(y_test_preds, axis=1))\n",
    "\n",
    "\n",
    "acc_per_class_no_graph = np.diag(cm/cm.sum(axis=0))\n",
    "\n",
    "# accuracy gain compared to no graph model\n",
    "sns.heatmap(acc_df - acc_per_class_no_graph,\n",
    "            cmap='RdBu_r',\n",
    "            vmin=-0.15,\n",
    "            vmax=0.15\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = model_fc.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, np.argmax(y_test_preds, axis=1))\n",
    "\n",
    "\n",
    "acc_per_class_fc = np.diag(cm/cm.sum(axis=0))\n",
    "\n",
    "# accuracy gain compared to FC model\n",
    "sns.heatmap(acc_df - acc_per_class_fc,\n",
    "            cmap='RdBu_r',\n",
    "            vmin=-0.15,\n",
    "            vmax=0.15\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv37-jax",
   "language": "python",
   "name": "venv37-jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
